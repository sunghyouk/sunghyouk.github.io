---
title:  "Mathematics for machine learning - Chapter 1: Introduction and motivation"
excerpt: "Introduction"

categories:
  - MATH
tags:
  - [mathematics, introduction, MML-book]

date: 2021-09-16
last_modified_at: 2021-10-10

toc: true
toc_sticky: true

---
## Foreword

- 머신러닝을 이해하면 - `linear algebra`, `analytic geometry`, `matrix decomposition`, `vector calculus`, `optimaization`, `probability`, and `statistics`가 필요하다.  
- 하지만, 모든 책과 전문가에게 분리되어 있다.  
- 그래서, 이것을 접합시켜서, `linear regression`, `principal component analysis`, `Gaussian mixture model`, and `support vector machine`을 유도하는 데 목적을 둔다.
- 각 장의 말미에 연습문제가 있고, 코딩에 대한 안내는 책의 웹페이지에 있다.  

## Preface

이 책은 모델 그 자체 뒤의 수학적 개념에 초점을 둔다  
머신러닝의 방법론과 모델에 초점을 둔 책에 관심이 있다면  

- MacKay, 2003: Information theory, Inference, and Learning algorithms.
- Bishop, 2006: Pattern recognition and machine learning.
- Alpaydin, 2010: Introduction to machine learning.
- Murphy, 2012: Machine learning: a probabilistic perspective.
- Barber, 2012: Bayesian reasoning and machine learning.
- Shalev-Shwartz and Ben-David, 2014: Understanding machine learning: From theory to algorithms.
- Rogers and Girolami, 2016: A first course in machine learning.

머신러닝의 프로그래밍 측면에 관심이 있다면

- Muller and Guido, 2016: Introduction to machine learning with Python: A guide for data scientists.
- Raschka and Mirjalili, 2017: Python machine learning: Machine learning and deep learning with Python, Scikit-learn, and TensorFlow.
- Chollet and Allaire, 2018: Deep learning with R

## Part I - Mathematical Foundations

### Chapter 1. Introduction and motivation

머신러닝은 데이터로부터 가치 있는 정보를 `automatically` 추출하는 알고리즘을 디자인하는 것이다.  
머신러닝의 세 가지 기본 요소로 : `data`, `model`, `learning`  

**머신러닝의 수학적 기초를 배운다**는 것이 중요한 이유

- 새 머신러닝 해법을 창조하고
- 기존 접근법을 이해하고 오류를 해결하며,
- 우리가 작업하고 있는 방법론에 내재된 가정과 한계점을 배울 수 있다.

#### 1.1 Finding words for intuitions

`Summary`

- We represent data as **vectors**.
  - 수학적 그리고 컴퓨터 과학적 관점에서
- We choose an appropriate model, either using the probabilistic or optimization view.
- We learn from available data by using numerical optimization methods with the aim that the model performs well on data not used for training.
  - 단지 training set에서 모델링 하여 높은 점수를 받은 것은 의미 없다.
  - 새 'unseen' 데이터가 들어 왔을 때 일반화된 머신러닝 모델이 얼마나 performance가 좋은 지를 알아야 한다.

#### 1.2 Two ways to read this book

##### Part I is about Mathematics

앞 장의 내용을 기반으로 쌓아 올려져서 차례대로 읽는 것이 좋다.

chapter 2: `linear algebra` - vector와 matrices
chapter 3: `analytic geometry` - similarity와 distances
chapter 4: `matrix decomposition`
chapter 5: `vector calculus`
chapter 6: `probability theory` 그리고 `distribution`
chapter 7: `optimization`

##### Part II is about Machine learning

넓게 보자면 뒤로 갈 수록 어려워 진다.

chapter 8: data, model, parameter estimation (learning) - 머신러닝 시스템이 과하게 긍정적인 평가를 주는 것을 방지하는 guidelines for building experimental setup
chapter 9: `linear regression` - maximum likelihood and maximum posteriori estimation의 관점에서
chapter 10: `dimensionality reduction` (principal component analysis)
chapter 11: `density estimation` (Gaussian mixture model) - 주어진 데이터셋을 묘사하는 확률 분포를 찾는 것에 목적
chapter 12: `classification` (Support vector machine)

#### 1.3 Exercises and feedback

##### Part I: 손과 펜으로 풀만한 것

##### Part II: jupyter notebook을 이용한 programming tutorial

[이 책의 pre-print 링크] (<https://mml-book.com>)
