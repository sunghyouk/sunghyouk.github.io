---
layout  : wiki
title   : "Introduction to GLM Chapter 6. 6.4"
summary : "6.4 Analysis of variance"
date    : 2022-01-10 10:42:49 +0900
updated : 2022-01-10 10:47:43 +0900
tag     : 
toc     : true
public  : true
parent  : [[2022-01-10-introduction_GLM]]
latex   : false
---

## 6.4 Analysis of variance

* Definition

Statistical methods for comparing means of groups of continuous observations where the groups are defined by the levels of factors.  
In this case all the explanatory variables are categorical and all the elements of the design matrix $\mathbf{X}$ are dummy variables.  

### 6.4.1 One factor analysis of variance

completetly randomized experiment
replicates
sum-to-zero constraint
corner point parameterization

### 6.4.2 Two factor analysis of variance

* Keywords

*ref)* sum of squares $\,=\,\mathbf{b^TX^Ty}$ (from page 93)  

crossed factor  
$L\, =\, 2$ observations or replicates  
saturated model  
reduced models  
interaction effects  
main effects  
additive model  
balanced: there are equal numbers of observations in each subgroup.
  * for balanced data it is possible to specify the design matrix in such a way that it is orthogonal [[6-2-5-Doc]]

```R
# In twofactor dataset
res.glmint = glm(data ~ A * B, family=gaussian, data=twofactor)
res.glmadd = glm(data ~ A + B, family=gaussian, data=twofactor)
res.glmA = glm(data ~ A, family=gaussian, data=twofactor)
res.glmB = glm(data ~ B, family=gaussian, data=twofactor)
res.glmmean = glm(data ~ 1, family=gaussian, data=twofactor)
```

