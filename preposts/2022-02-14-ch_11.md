---
layout  : wiki
title   : "An introduction to GLM Chapter 11"
summary : "Chapter 11. Clustered and longitudinal data"
date    : 2022-02-14 06:22:36 +0900
updated : 2022-02-15 07:34:35 +0900
tag     : 
toc     : true
public  : true
parent  : [[2022-01-10-introduction_GLM]]
latex   : false
---

## 11.1 Introduction

The term repeated measures is used to describe both longitudinal and clustered data.  
1) Dropping the usual assumption of independence - repeated measures and the generalized estimating equation approach
2) multilevel modelling - outcomes at the same level are assumed to be independent and the correlation is a result of the multilevel structure.

It is necessary to choose a correlation structure likely to reflect the relationships between the observations.  
Correlation parameters - in order to obtain consistent estimates of those parameters that are of interest and to correctly calculate the SE of these estimates.  

Multilevel models - by fixed parameters (e.g., for group effect) or random variables (E.g., for subjects randomly allocated to groups). - mixed model  

## 11.2 Example: Recovery from stroke

A naive analysis, sometimes called a pooled analysis, of these data is to fit an analysis of covariance model.  
* Equation 11.1  
$$E(Y_{ijk}) = \alpha_i + \beta t_k + e_{ijk}$$

The slopes may differ between the groups  
* Equation 11.2  
$$E(Y_{ijk}) = \alpha_i + \beta_i t_k + e_{ijk}$$

## 11.3 Repeated measures models for Normal data

A normal linear model for $\mathbf{y}$ is  
* Equation 11.3
$$E(\mathbf{y}) = \mathbf{X}\boldsymbol{\beta} = \boldsymbol{\mu};\, \mathbf{y}\sim MVN(\boldsymbol{\mu}, \mathbf{V})$$

The maximum likelihood estimator is obtained by solving the score equations  
* Equation 11.4
$$\mathbf{U}(\boldsymbol{\beta})=\frac{\partial{l}}{\partial{\boldsymbol{\beta}}}=\mathbf{X}^T\mathbf{V}^{-1}(\mathbf{y}-\mathbf{X}\boldsymbol{\beta})=\sum_{i=1}^N \mathbf{X}_i^T\mathbf{V}_i^{-1}(\mathbf{y}_i - \mathbf{X}_i\boldsymbol{\beta})=\mathbf{0}$$

The solution is  
* Equation 11.5
$$\hat\boldsymbol\beta=(\mathbf{X}^T\mathbf{V}^{-1}\mathbf{X})^{-1}\mathbf{X}^T\mathbf{V}^{-1}\mathbf{y}=(\sum_{i=1}^N \mathbf{X}_i^T\mathbf{V}_i\mathbf{X}_i)^{-1}(\sum_{i=1}^N\mathbf{X}_i^T\mathbf{V}_i^{-1}\mathbf{y}_i)$$

with  
$$var(\hat\boldsymbol\beta)=(\mathbf{X}^T\mathbf{V}^{-1}\mathbf{X})^{-1}=(\sum_{i=1}^N\mathbf{X}_i^T\mathbf{V}_i^{-1}\mathbf{X}_i)^{-1}$$

and $\hat\boldsymbol\beta$ is asymptotically Normal (NOTE: Chapter 6)  

$\mathbf{V}_s(\boldsymbol\beta)$ is called the **information sandwich estimator**, because $\mathfrak{J}$ is the information matrix (NOTE: Chapter 5).  
**Huber estimator** is a consistent estimator of var$(\hat\boldsymbol\beta)$ when $\mathbf{V}$ is not known, and it is robust to mis-specification of $\mathbf{V}$.  

1. All the off-diagonal elements are equal  
   * Equation 11.7
   * clusted data where it is plausible that all measurements are equally correlated
   * $\rho$: intra-class correlation coefficient
2. off-diagonal terms decrease with distance between observation  
   * first order autoregressive model with $\rho^{|j-k|}$, where $|\rho|<1$
   * Equation 11.8, 11.9
3. All the correlation terms may be different  
   * Unstructured correlation matrix

Some programs treat repeated measures as a special case of multivariate data - This is especially inappropriate for longitudinal data in which the time order of the observations matters. (REF: https://onlinelibrary.wiley.com/doi/epdf/10.1002/%28SICI%291097-0258%2820000330%2919%3A6%3C861%3A%3AAID-SIM407%3E3.0.CO%3B2-F)

## 11.4 Repeated measures models for non-Normal data

from score equation (NOTE: Equation 4.18)  
* Equation 11.11
$$U_j = \sum_{i=1}^N \frac{(y_i-\mu_i)}{var(Y_i)} \frac{\partial\mu_i}{\partial\beta_j}=0,\, j=1,...,p.$$

Let $\mathbf{D}_i$ be the matrix of derivatives $\partial\boldsymbol\mu_i/\partial\beta_j$.  
To simplify the notation, assume that all the subjects have the same number of measurements $n$.  
The **Generalized Estimating Equations** analogous to equation (11.11) are  

* Equation 11.12
$$\mathbf{U}=\sum_{i=1}^N \mathbf{D}_i^T\mathbf{V}_i^{-1}(\mathbf{y}_i - \boldsymbol\mu_i) = \mathbf{0}.$$

These are also called quasi-score equations.  
There are a number of complications that occure in practice.  

## 11.5 Multilevel models

Let $Y_{jk}$ denote the response of the $k$th subject in the $j$th cluster.  
* Equation 11.13
$$Y_{jk} = \mu+a_j+e_{jk}$$

This is an example of a mixed model with both fixed and random effect. The parameters of interest are $\mu$, $\sigma_a^2$, \sigma_e^2$ (and hence $\rho$).  
* Equation 11.14
$$Y_{jk} = \beta_0 + a_j + (\beta_1+b_j)t_k + e_{jk}$$

In general, mixed models for Normal responses  
* Equation 11.15
$$\mathbf{y} = \mathbf{X}\beta + \mathbf{Zu} + \mathbf{e},$$
$\mathbf{Zu}$ describes the between-subjects random effects and $\mathbf{e}$ the within-subjects random effects.  
The variance-covariance matrix for $\mathbf{y}$ is  
* Equation 11.16
$$\mathbf{V(y)}=\mathbf{ZG}^T\mathbf{Z}+\mathbf{R}$$

## 11.6 Stroke example continued

`geepack` library for GEE  
`nlme` library for random effects model  

## 11.7 Comments


