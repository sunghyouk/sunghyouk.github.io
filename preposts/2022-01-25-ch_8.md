---
layout  : wiki
title   : "Introduction to GLM Chapter 8"
summary : "Chapter 8. Nomial and ordinal logistic regression"
date    : 2022-01-25 06:59:39 +0900
updated : 2022-01-26 11:40:03 +0900
tag     : 
toc     : true
public  : true
parent  : [[2022-01-10-introduction_GLM]]
latex   : false
---

 # Chapter 8. Nomial and ordinal logistic regression

## 8.1 Introduction

If the response variable is categorical, with more than two categories.  
One relies on generalization of logistic regression from dichotomous responses, to nomial or ordinal responses with more than two categories. (GOTO: Chapter 7.)  
The other option is to model the frequencies or counts for the covariate pattern as the response variables with Poisson distributions. - **log-linear modelling** (GOTO: Chapter 9.)  

One of the measured or observed categorical variables is regarded as the response, and all other variables are explanatory variables.  

Whether one variable is clearly a "response" or several variables have the same status.  
How the results are to be presented and interpreted.

## 8.2 Multinomial distribution

Consider a random variable $Y$ with $J$ categories. Let $\pi_1$, $\pi_2$, ..., $\pi_J$ denote the respective probabilities.  
The Multinomial distribution is (Equation 8.1):  
$$f(\mathbf{y}| n)=\frac{n!}{y_1!y_2!...,y_J!}\pi_1^{y_1}\pi_2^{y_2}...\pi_J^{y_J}$$

The following relationship with the Poisson distribution ensures that GLM is appropriate.  
Let $Y_1,...,Y_J$ denote independent random variables with distribution $Y_j\tilde Po(\lambda_j)$.  
Their joint probability distribution is (Equation 8.2):  
$$f(\mathbf{y})=\mathrm{\Pi}_{j=1}^J\frac{\lambda_j^{y_j}e^{-\lambda_j}}{y_j!}$$

The distribution of $\mathbf{y}$ conditional $n$ is (Equation 8.3):  
$$f(\mathbf{y}|n)=\left(\frac{\lambda_1}{\sum\lambda_k}\right)^{y_1}...\left(\frac{\lambda_J}{\sum\lambda_k}\right)^{y_J}\frac{n!}{y_1!...,y_J!}$$

> The Multinomial distribution can be regarded as the joint distribution of Poisson random variables, conditional upon their sum $n$.

## 8.3 Nomial logistic regression

When there is no natural order among the response categories. One category is arbitrarily chosen as the **reference category**.  
* Equation 8.4
$$logit(\pi_j)=\log\left(\frac{\pi_j}{\pi_1}\right)=\mathbf{x}_j^T\mathbf{\beta}_j,\,for\,j=2,...,J$$

Pearson chi-squared residuals (Equation 8.5):  
$$r_i=\frac{o_i=e_i}{\sqrt{e_i}}$$

Summary statistics for goodness of fit  are analogous to those for Binomial logistic regression (from Equation 8.6 to Equation 8.10):  
1) Chi-squared statistic:  
   $$X^2=\sum_{i=1}^N r_i^2$$
2) Deviance:  
   $$D=2\left[l(\mathbf{b}_{max})-l(\mathbf{b})\right]$$
3) Likelihood ratio chi-squared statistic:  
   $$C=2\left[l(\mathbf{b})-l(\mathbf{b}_{min})\right]$$
4) Pseudo $R^2$:  
   $$\frac{l(\mathbf{b}_{min})-l(\mathbf{b})}{l(\mathbf{b}_{min})}$$
5) Akaike information criterion:  
   $$AIC=-2l(\mathbf{\hat\pi;\mathbf{y}})+2p

If the model fits well, then both $X^2$ and $D$ have, asymptotically, the distribution $\chi^2(N-p)$, where $p$ is the number of parameters estimated.  
$C$ has the asymptotic distribution $\chi^2[p-(J-1)]$ because the minimal model will have one parameter for each logit defined in (8.4)  
$AIC$ is used mainly for comparisons between models which are not nested.  

