---
layout  : wiki
title   : "Introduction to GLM Chapter 8"
summary : "Chapter 8. Nomial and ordinal logistic regression"
date    : 2022-01-25 06:59:39 +0900
updated : 2022-01-31 10:36:50 +0900
tag     : 
toc     : true
public  : true
parent  : [[2022-01-10-introduction_GLM]]
latex   : false
---

 # Chapter 8. Nomial and ordinal logistic regression

## 8.1 Introduction

If the response variable is categorical, with more than two categories.  
One relies on generalization of logistic regression from dichotomous responses, to nomial or ordinal responses with more than two categories. (GOTO: Chapter 7.)  
The other option is to model the frequencies or counts for the covariate pattern as the response variables with Poisson distributions. - **log-linear modelling** (GOTO: Chapter 9.)  

One of the measured or observed categorical variables is regarded as the response, and all other variables are explanatory variables.  

Whether one variable is clearly a "response" or several variables have the same status.  
How the results are to be presented and interpreted.

## 8.2 Multinomial distribution

Consider a random variable $Y$ with $J$ categories. Let $\pi_1$, $\pi_2$, ..., $\pi_J$ denote the respective probabilities.  
The Multinomial distribution is (Equation 8.1):  
$$f(\mathbf{y}| n)=\frac{n!}{y_1!y_2!...,y_J!}\pi_1^{y_1}\pi_2^{y_2}...\pi_J^{y_J}$$

The following relationship with the Poisson distribution ensures that GLM is appropriate.  
Let $Y_1,...,Y_J$ denote independent random variables with distribution $Y_j\tilde Po(\lambda_j)$.  
Their joint probability distribution is (Equation 8.2):  
$$f(\mathbf{y})=\mathrm{\Pi}_{j=1}^J\frac{\lambda_j^{y_j}e^{-\lambda_j}}{y_j!}$$

The distribution of $\mathbf{y}$ conditional $n$ is (Equation 8.3):  
$$f(\mathbf{y}|n)=\left(\frac{\lambda_1}{\sum\lambda_k}\right)^{y_1}...\left(\frac{\lambda_J}{\sum\lambda_k}\right)^{y_J}\frac{n!}{y_1!...,y_J!}$$

> The Multinomial distribution can be regarded as the joint distribution of Poisson random variables, conditional upon their sum $n$.

## 8.3 Nomial logistic regression

When there is no natural order among the response categories. One category is arbitrarily chosen as the **reference category**.  
* Equation 8.4
$$logit(\pi_j)=\log\left(\frac{\pi_j}{\pi_1}\right)=\mathbf{x}_j^T\mathbf{\beta}_j,\,for\,j=2,...,J$$

Pearson chi-squared residuals (Equation 8.5):  
$$r_i=\frac{o_i=e_i}{\sqrt{e_i}}$$

Summary statistics for goodness of fit  are analogous to those for Binomial logistic regression (from Equation 8.6 to Equation 8.10):  
1) Chi-squared statistic:  
   $$X^2=\sum_{i=1}^N r_i^2$$
2) Deviance:  
   $$D=2\left[l(\mathbf{b}_{max})-l(\mathbf{b})\right]$$
3) Likelihood ratio chi-squared statistic:  
   $$C=2\left[l(\mathbf{b})-l(\mathbf{b}_{min})\right]$$
4) Pseudo $R^2$:  
   $$\frac{l(\mathbf{b}_{min})-l(\mathbf{b})}{l(\mathbf{b}_{min})}$$
5) Akaike information criterion:  
   $$AIC=-2l(\mathbf{\hat\pi;\mathbf{y}})+2p

If the model fits well, then both $X^2$ and $D$ have, asymptotically, the distribution $\chi^2(N-p)$, where $p$ is the number of parameters estimated.  
$C$ has the asymptotic distribution $\chi^2[p-(J-1)]$ because the minimal model will have one parameter for each logit defined in (8.4)  
$AIC$ is used mainly for comparisons between models which are not nested.  

### 8.3.1 Example: Car preferences

The maximum value of the log-likelihood function for the minimal model  
Fitted model (8.11)  
: calculating statistic C, pseudo $R^2$, $AIC$  
: Pearson residuals  

The maximal model that can be fitted to these data involves terms for age, sex, and age $\times$ sex interactions.  
: deviance  
: statistics D and $\Chi^2$  

Alternative model : two fewer parameters  
: calculating difference in deviance $\Delta D$  
: On the grounds of parsimony, alternative model is preferable.  

## 8.4 Ordinal logistic regression

If there is an obvious natural order among the response categories.  
There may, conceptually, be a continuous variable $z$, such as severity of disease, which is difficult to measure. It is assessed by some crude method that amounts to identifying "cut points", $C_j$, for the **latent variable**.

### 8.4.1 Cumulative logit model

* Equation 8.13
$$\log\frac{\pi_1+...+\pi_j}{\pi_{j+1}+...+\pi_J}=\mathbf{X}_j^T\beta_j$$

### 8.4.2 Proportional odds model

If the linear predictor in (8.13) has an intercept term $\beta_{0j}$ which depends on the category $j$.: **Proportional odds model**  
* Equation 8.14
$$\log\frac{\pi_1+...+\pi_j}{\pi_{j+1}+...+\pi_J}=\beta_{0j}+\beta_1x_1+...+\beta_{p-1}x_{p-1}$$
Assumption: The effects of the covariates are the same for all categories on the logarithmic scale.

Collapsibility property: This form of independence between the cutpoints $C_j$ and the explanatory variables $x_k$ is desirable for many applications.  
If the labelling of the categories is reversed - only the signs of the parameters will be changed.  
The proportional odds model is the usual (or default) form of ordinal logistic regression.  

### 8.4.3 Adjacent categories logit model

ratios of probabilities for successive categories,  
* Equation 8.15
$$\log\left(\frac{\pi_j}{\pi_{j+1}}\right)=\mathbf{x}_j^T\beta_j$$

### 8.4.4 Continuation ratio logit model

* Equation 8.16
$$\log\left(\frac{\pi_j}{\pi_{j+1}+...+\pi_J}\right)=\mathbf{x}_j^T\beta_j$$
models the odds of the response being in cartegory $j$.  

This model may be easier to interpret if the probabilities for individual cartegories $\pi_j$ are of interest.  

### 8.4.5 Comments

Hypothesis tests can be performed by comparing the fit of nested models or by using Wald statistics.  
Residuals and goodness of fit statistics are analogous to those for nominal logistic regression (GOTO: Section 8.3).  
The choice of model for ordinal data depends mainly on the practical problem being investigated.  

### 8.4.6 Example: Car preferences

The proportional odds logistic model for ordinal data and the nominal logistic model produce similar results.  
On the grounds of parsimony, model (8.17) would be preferred because it is simpler and takes into account the order of the response categories.

## 8.5 General comments

The optimal choice of the link function can depend on the shape of the distribution of $z$. Logistic and probits are appropriate if the distribution is symmetric but the complementary log-log link may be better if the distribution is very skewed.  
If there is doubt about the order of the categories, then nominal logistic regression will usually be a more appropriate model.  

## 8.6 Excercises


