---
layout  : wiki
title   : "Federated learning Chapter 1."
summary : "Chapter 1. Introduction"
date    : 2022-01-10 17:23:47 +0900
updated : 2022-01-10 17:24:46 +0900
tag     : 
toc     : true
public  : true
parent  : [[2022-01-10-FL_1]]
latex   : false
---

# Chapter 1. Introduction

## 1.1 Motivation

만족스러울만한 AI application을 만들기 위해 데이터가 많이 필요하다.  
하지만, 이에 적절한 답지가 모두 붙어 있거나 결측이 없는 데이터를 구하기는 쉽지 않다.  
이를 위해, 인력과 시간이 많이 필요하다. 특히, 적절한 label을 완성하기 위해 domain expert가 필요하니 자원이 더 많이 필요하다.  

데이터가 다른 기관과 조직에 의해 생성되고 소유되기 때문에 전통적이고 순진한 접근은 강력한 컴퓨터가 훈련하고 ML 방법론을 구축할 하나의 중앙에 데이터를 모으고 전송한다. 오늘날 이 방법론은 더 이상 유효하지 못하다.  

EU에서 2018년 General Data Protection Regulation (GDPR)을 제정,  
미국에서 2020년 California Consumer Privacy Act (CCPA) 제정됨  

법적인, 행정적인 절차, 금융 데이터나 건강 정보에 관한 개인들의 우려, 비용 등의 문제로 데이터를 모으는 것은 거의 불가능한 일이 되었다.  

이 문제를 적절히 제기하는 데 실패하면 새 AI 겨울을 맞이할 수도 있다.  

하지만, 이 외에도 빅 데이터의 공유를 넘어 협력하는 것의 이득이 명확하지 않다. 데이터가 문 밖에 나서는 순간 데이터 소유 기관의 영향력이 감소하며,   
데이터 통제를 상실하고, 가치의 분배를 결정하는 투명성의 부족은 소위 파편화를 심화시키는 원인이 되고 있다.  

보안이 확보된 하지만 효율적으로 여러 위치 사이에서 모델의 엽데이트와 공유를 어떻게 가능하게 하는가는 현재 컴퓨팅 방법론의 새 숙제이다.  

## 1.2 Federated learning as a solution

**연합학습**: 데이터 소스가 있는 각 장소에서 모델을 훈련하고 글로벌 모델에 대한 동의에 이르기 위해 각 모델을 통신하도록 하자는 아이디어가 떠올랐다.  
  - 사용자 프라이버시와 데이터 신뢰를 확실하게 하기 위해 통신 과정은 다른 장소의 개인 데이터를 예측할 수 없도록 조심스럽게 처리되며,
  - 동시에, 모델은 모든 소스가 합쳐진 것처럼 구축된다.  

B2C (business-to-consumer)의 응용에 대한 보안된 분산 학습 환경을 고안하여 구글의 Gboard는 좋은 예를 보여준다. - *FedAvg*  
말단 기기와 중앙 서버 사이 정보를 전송하는 데 속도가 빨라지면서 퍼포먼스가 향상될 뿐만 아니라 프라이버시 보호도 확실히 된다.  

### 1.2.1 The definition of federated learning

Federated learning의 목표는 다양한 사이트에 위치한 데이터에 기반한 합동 ML 모델을 구축하는 것이다.  
두 공정: 모델 훈련, 모델 추론  
마지막으로 공정한 가치 분배 메커니즘이 있어야 지속가능한 연합을 만들 수 있다.
  - 모델을 훈련하는 데 기여하고자 하는 데이터를 지닌 몇몇 파티가 있다.
  - 모델 훈련 공정에서 각 파티의 갖고 있는 데이터는 그 파티를 떠나지 않는다.
  - 한 파티에서 다른 쪽으로 암호화된 개요 아래 전송되어 다른 파티에서 재공정될 수 없다.
  - 결과 모델의 퍼포먼스는 단일 파티로 전송된 모든 데이터로 구축된 이상적 모델에 접근한다.

수식으로 표현하면,  
각자 데이터셋 $D_i$을 가지고 있는 $N$개의 데이터 소유자 $F_i$가 전통적인 방법으로 만든 모델 $M_{SUM}$  
연합 학습으로 만든 모델은 $M_{FED}$로 표현,  
그 성능을 각각 $V_{SUM},\,V_{FED}$로 표현,  
성능의 차를 음이 아닌 실수 $\delta$로 설정하면,  
$$|V_{SUM}-V_{FED}|<\delta$$  

직관적으로 보자면, 미래의 데이터에 대한 모델의 퍼포먼스는 모든 데이터 소스를 모두 합쳐 구축한 모델에 근접할 것이다.  
연합학습 시스템은 애플리케이션에 따라 중앙의 조율 컴퓨터를 포함할 수도 있고 아닐 수도 있다.  
조율하는 컴퓨터를 중앙 집적 서버 (파라미터 서버), 데이터 소유자는 클라이언트 또는 참여자로 불린다.  

로컬 데이터 소유자는 각자 데이터셋을 이용해 모델을 훈련하고 가중치를 집적 서버에 보낸다.  
집적 서버는 데이터 소유자로부터 받은 모델 업데이트를 합친다.  
그리고 로컬 데이터 소유자에게 합쳐진 모델 업데이트를 돌려 보낸다.  
이를 모델이 수렴할 때까지 혹은 최대 이터레이션에 도달할 때까지 수행한다.  

이 방법은 사용자의 프라이버시와 데이터 보안을 침해하지 않을 뿐아니라 원시 자료를 보내 통신 과부하를 막을 수 있다.  
정보 유출에 대항하기 위해 로컬 데이터 소유자와 중앙 집적 서버 사이의 통신은 암호화된 데이터를 통신할 수 있다.  

peer-to-peer 방식으로 통신할 수도 있는데, 이는 중앙 집적 서버가 필요하지 않다.  
보안을 향상시킬 수 있지만, 암호화와 해독하는데 더 많은 컴퓨팅이 필요할 수 있다.  

몇 가지 이득이 있다.
1) 데이터 전송이 요구되지 않는다.
2) 단일 기관에서 얻을 수 있는 것 보다 더 좋은 모델이 생성될 수 있다.

몇 가지 험난한 점이 있다.
1) 로컬 데이터 소유자와 집적 서버 간 통신 연결이 느려지거나 불안정할 수 있다.
2) 이론적으로 모든 기기 사용자가 연합 학습에 참여할 수 있어서, 데이터가 non-identical distribution을 따를 수 있다.
    * 이는 데이터 샘플의 불균형으로 인해 편향된 모델을 만들 수 있고, 모델을 훈련시키는 것을 실패하게 만들 수 있다.
3) poisoning attack: 하나 이상의 악성 참여자가 악의의 모델 업데이트를 보내 전체 기능을 혼란스럽게 만들 수 있다.

### 1.2.2 Categories of federated learning


