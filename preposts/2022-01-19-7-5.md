---
layout  : wiki
title   : "Introduction to GLM Chapter 7-5"
summary : "Chapter 7-5 Goodness of fit statistics"
date    : 2022-01-19 07:16:08 +0900
updated : 2022-01-19 11:11:32 +0900
tag     : 
toc     : true
public  : true
parent  : [[2022-01-10-introduction_glm]]
latex   : false
---

# Chapter 7-5 Goodness of fit statistics

We could estimate the parameters by minimizing the weighted sum of squares  
This is equivalent to minimizing the **Pearson chi-squared statistic**  
$$X^2=\sum\frac{(o-e)^2}{e},$$
카이 제곱 값이 추정된 기대 도수에서 평가되었을 때 통계량은,  
Equation 7.6:  
$$X^2=\sum_{i=1}^N\frac{(y_i-n_i\hat\pi_i)^2}{n_i\hat\pi_i(1-\hat\pi_i)}$$

different covariate pattern is zero to one, then neither Deviance nor chi-squarre provides a useful measure of fit.  
This can happen if the explanatory variables are *continuous*.  

to group observation into categories, typically about 10 groups are used with approximately equal numbers of observations in each group.  
**Hosmer-Lemeshow statistic** by $X^2_{HL}$  

Under the **minimal model** (values $\pi_i$ are all equal) $\tilde\pi=(\sum{y_i})/(\sum{n_i})$. - 이와 우리의 관심 모델을 비교  
Thus C is a test statistic for the hypothesis that none of the explanatory is needed for a parsimonious model. - **likelihood ratio chi-squared statistic**

pseudo $R^2$ presents the proportional improvement compared with the minimal model.  
하지만, 개인 outcome을 표현하기 때문에 log-likelihood function에 기반 - 파라메터의 수와 데이터의 총량에 대한 보정을 한, **AIC**, **BIC**를 사용  


