---
layout  : wiki
title   : "쏙쏙 들어오는 인공지능 알고리즘 Chapter 9"
summary : "Chapter 9. 인공 신경망"
date    : 2022-02-19 22:03:53 +0900
updated : 2022-02-24 10:12:04 +0900
tag     : 
toc     : true
public  : true
parent  : [[2022-01-07-Grokking_AI_algorithm]]
latex   : false
---

## 인공 신경망이란?

특징이 서로 어떻게 관련되어 있는지 이해하기 어려운 구조화되지 않은 데이터에 가장 적합하다.  

## 퍼셉트론: 뉴런의 개념적 표현

* 입력
* 가중치 - 입력노드와 은닉노드 사이의 각 연결에 대한 가중치
* 은닉노드 (합산 및 활성화)
* 출력

`활성화 함수` - 시그모이드 함수를 이용, 선형 문제를 해결하는 데 도움  
직선으로 분류할 수 없으면 퍼셉트론은 실패한다.  

## 인공 신경망 정의

`다층 인공 신경망`: 퍼셉트론의 원칙을 단일 노드가 아닌 많은 은닉노드에 적용.  
최소-최대 크기 조정 방법으로 데이터 전처리  
입력 노드: 특정 견본에 대한 값을 저장하는 단일 배열로 표시  
가중치: 행렬 (2차원 배열)로 나타낼 수 있다.  
은닉노드: 각 노드의 활성화 결과를 저장하는 단일 배열로 표시  
출력노드: 특정 견본에 대해 예측한 클래스 또는 견본이 특정 클래스에 있을 가능성을 나타내는 하나의 값  

## 순전파: 훈련된 인공 신경망 사용

새로운 견본에 대한 클래스를 가장 잘 예측할 수 있도록 가중치를 조정한 네트워크  
**수계산**이 가장 인상적임  

## 역전파: 인공 신경망 훈련

### A단계: 설정

1) 인공 신경망 구조 정의
2) 인공 신경망 가중치 초기화

### B 단계: 순전파

예측한 출력은 훈련용 학습 세트의 각 견본에 대한 실제 클래스와 비교

### C 단계: 훈련

1) 비용 계산
2) 인공 신경망의 가중치 업데이트 - 인공 신경망의 가중치는 네트워크 자체에서 조정할 수 있는 유일한 매개변수
3) 중지 조건 정의  
   * `미니 배치`: 여러 개의 작은 그룹으로 나누어서 모델을 훈련
   * `배치 크기`: 미니 배치의 크기
   * `에포크`: 전체 훈련 데이터로 1번 훈련을 마치는 것을 1 에포크
   * `반복` (iteration): 1 에포크를 마치는 데 필요한 미니 배치의 개수

`경사하강법`: 경사에 대한 지식을 이용해서 어느 방향으로 얼마나 이동해야 하는지를 결정  

`입자 군집 최적화`도 사용할 수 있다. 다양한 접근 방식이 있다.  

## 활성화 함수 선택

* 단위 계단 - 이진 분류를 위한 출력 레이어에서 사용
* 시그모이드 - x의 값이 양 극단으로 갈수록 기울기 벼노하가 작아져 학습 능력이 떨어짐 (vanishing gradient problem)
* 쌍곡 탄젠트 - 시그모이드보다 기울기가 급해서 더 빠르게 학습할 수 있음
* 정류 선형 단위 (ReLU) - 일부 뉴런이 활성화되지 않도록 해서 계산을 줄이고 솔루션을 더 빨리 찾을 수 있음

## 인공 신경망 설계

* 입력 및 출력
* 은닉층 및 노드
* 가중치
* 편향
* 활성화 함수
* 비용 함수 및 학습률

## 인공 신경망 및 사용 사례

* 합성곱 신경망: 이미지
* 순환 신경망: 음성과 텍스트 인식
* 적대적 신경망

