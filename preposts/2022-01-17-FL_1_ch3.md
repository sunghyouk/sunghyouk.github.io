---
layout  : wiki
title   : "Federated learning Chapter 3"
summary : "Chapter 3. Distributed machine learning"
date    : 2022-01-17 17:32:14 +0900
updated : 2022-01-19 16:38:30 +0900
tag     : 
toc     : true
public  : true
parent  : [[2022-01-10-FL_1]]
latex   : false
---

# Chapter 3. Distributed machine learning

FL and distributed ML share several common features, e.g., both employing decentralized datasets and distributed training.  
> FL: seen as the future and the next step of *DML*  

distributed storage of training data  
distributed operation of computing task  
distributed serving of model results, etc.  

## 3.1 Introduction to DML

### 3.1.1 The definition of DML

Definition: *multi-node* ML or DL algorithms and systems that are designed to improve performance, preserve privacy, and scale to more training data and bigger models.  
일꾼들은 그래디언트 $\Delta\mathbf{w}^i$ 혹은 $\mathbf{w}^i$를 파라메터 서버에 전송하여 global gradients $\Delta\mathbf{w}$ 혹은 모델 가중치 $\mathbf{w}$를 얻는다.  

DML의 큰 분류 두가지:  
*scalability-motivated DML* - ML과 DL 방법이 다뤄야 하는 문제의 스케일이 지수적으로 증가. 큰 총량의 데이터로 복잡한 DL 모델을 훈련하는 것은 단일 컴퓨팅 기기에 의존하는 기존 ML 패러다임의 수용력을 쉽게 초과할 수 있다. 이를 타개하기 위해 multiple tensor processing units (TPUs)가 대안으로 제시되어 해답으로 여겨지고 있다. 이는 클라우드 컴퓨팅의 시대에 도움이 되는 것이며 **수평으로 나누어진 데이터셋**에 널리 적용될 수 있다.  
*privacy-motivated DML* - ML 모델을 협동하여 훈련하기 위해 각 참여하는 파티의 데이터를 사용하도록 요구 받는다. 즉, 다른 파티들이 소유한 다른 속성으로 데이터를 훈련 시키는 부분 집합으로, **수직으로 파티션된 데이터셋**으로 작업하는 시나리오에서 자주 적용될 수 있다.  

### 3.1.2 DML platforms

Apache Spark MLlib  
GraphLab  
Apache Spark GraphX  

Distributed ML Toolkit (DMLT) - released by Microsoft  
Tensorflow (tf.distribute) - i) 다른 프로세스 심지어 다른 서버에서 계산된 그래프의 일부를 허용, ii) 입력 데이터셋의 다른 조각을 넘어 같은 모델을 훈련하는데 다중 프로세서 심지어 다른 서버를 고용할 수 있다.  
PyTorch (torch.multiprocessing package)  

## 3.2 Scalability-motivated DML

### 3.2.1 Large-scale ML

데이터는 광대한 볼륨으로 어디에나 흩어져 있다. 데이터는 커지지만 몇 가지 난관에 부딫히게 되었는데, 주요 난제는 다음과 같다.  
1) 메모리 부족: 한 컴퓨터로 전체 데이터를 합쳐서 샘플을 훈련시키게 되면 i) 훈련된 모델이 수렴하지 못하거나 낮은 예측력을 보일 수 있고 ii) 메모리 부족으로 아예 모델을 훈련시킬 수 없을 가능성이 있다.
2) 말도 안되는 훈련 시간: 하이퍼파라메터 튜닝이 많은 다른 세팅을 실험해야 하므로 시간이 많이 걸린다.

분산 ML 알고리즘은 대규모 학습 알고리즘의 일부이다.

### 3.2.2 Scalability-oriented DML schemes

훈련 시간을 줄이고, 대규모의 DL 모델을 다루는 데 목적을 둔 수많은 연구가 진행되어 왔다.  

#### Data parallelism

훈련 데이터를 부분 집합으로 만들어 다중의 컴퓨팅 기기에 넣어 평행하게 같은 모델을 훈련시킨다는 관점이다. - data-centric approach  
다른 말로, 다른 컴퓨팅 기기에 같은 모델의 다중 복제본을 통해 데이터를 훈련시키는 다중 데이터 조각을 프로세싱하는 것이다.  
하지만 단일 기기에 있어야만 하는 모델의 복제본이기 때문에 고 메모리로 ML 모델을 다룰 수 없다.  
두 가지 접근 방식이 있다:  
1) 동기화 훈련: 각 훈련 단계가 기기에 의해 수행된 이후 기울기 혹은 모델 가중치가 집적된다.
2) 비동기화 훈련: 이 과정이 비동기식으로 진행

동기화는 AllReduce architecture, 비동기화는 parameter server architecture에 의해 훈련된다.  

#### Model parallelism

모델이 커지면 커질수록 (예를 들어, BERT 모델같이) DNN 모델을 단일 컴퓨팅 기기의 메모리에 적재할 수 없다.  
이런 시나리오에서, 모델을 잘라내서 모델의 일부를 다른 기기에 집어 넣는다. - model-centric approach  
AMPNet  
OptCNN: layer-wise parallelism
downpour SGD - combines data parallelism and model parallelism  
DeepSpark  

#### Graph parallelism

graph-centric approach  
GraphLab - 데이터 일관성을 유지하면서 산포되어 있는 계산 의존성으로 비동기화 반복 알고리즘을 고안, 대규모 실제 ML 작업에 훌륭한 성능을 보여줌  
TUX$^2$

#### Task parallelism

task-centric approach: 같은 혹은 다중의 기기에 다중의 프로세서를 경유해 컴퓨터 프로그램의 실행  
Apache Storm  
Apache YARN  

#### Hybrid parallelism and mixed parallelism

Apache YARN  
SystemML  
Google downpour SGD  
SOYBEAN system - performs automatic parallelization  

## 3.3 Privacy-motivated DML

의료 영역에서 병원이나 의료 기관은 규제에 따라 의료 데이터를 공유하는 것이 금지 되어 있다.  
이런 이유로, 다음과 같은 정보를 일반적으로 보호한다:  
1) 입력 훈련 데이터
2) 출력된 예측 라벨
3) 모델의 정보, 파라메터와 구조, 손실함수 등을 포함하여,
4) 식별 가능한 정보 - 기록이 수행된 장소와 같은

### 3.3.1 Privacy-preserving decision trees

데이터 분산에 따라 두 범주로 나눈다:  
1) 수평 분리된 데이터셋
2) 수직 분리된 데이터셋

수평으로 분리된 셋은 다른 샘플을 소유하고 있고 모든 기기의 샘플은 같은 속성 범주를 가지고 있다.  
수직으로 분리된 셋은 속성이 다르지만 같은 사용자군을 참조하고 있을 가능성이 높다.  
다른 ML 알고리즘과 다르게, 결정 트리에서 데이터 분리는 중요하다.  
oblivious secure protocol로 다른 참여자에게 각 값을 노출하지 않고 수평으로 분리된 데이터셋에 분산 결정 트리 알고리짐을 제안하였다.  
이후 수직으로 분리된 데이터셋도 partially HE, DP를 이용해 훈련시키는 데에 성공하였으며 성능도 좋았다.  

### 3.3.2 Privacy-preserving techniques

1) Obfuscation: 특정 개인 정보 수준을 감추기 위해 데이터를 섞거나 변형 - DP
2) Cryptographic methods: 다른 참여자에게 입력 값을 노출하지 않도록 분산 컴퓨팅 공정을 보안 - MPC, OT, SS, GC, HE

> GOTO: section 2.4

### 3.3.3 Privacy-preserving DML schemes

결론적으로, 계산 효율성과 편리한 고안에 의해, obfuscation 기반 개인정보 보호 기술이 인기가 있다.  
하지만, perturbation은 데이터와 모델의 이용에 영향을 미친다. 실제로 연구자들은 개인 정보 보호와 성능 사이에서 거래를 해야한다.  
암호화 방법은 데이터의 정확도와 모델 성능을 희생할 필요가 없다.  

DL에 있어서 가장 대표적인 작업은 SecureAggregation이다. 이 작업은 **FedAvg**에 기반을 두고 있다.

## 3.4 Privacy-preserving gradient descent

가장 높은 수준의 데이터 보호와 보안을 하려는 방법론은 대부분 HE와 MPC를 체택한다.  
전형적인 개인정보보호 경사 하강 방법은 naive FL, algebraic/sparse gradient update, obfuscation/cryptographic 방법 등이 있다.  

### 3.4.1 Vanilla FL

**FedAvg** was first employed for FL over horizontally partitioned dataset. Each party uploads *clear-text gradeint* to a parameter server independently, then coordinator computes the average of the gradients and update the model. Finally, the coordinator sends the clear-text updated model back to each party.  
The objective function can be decomposed into a *differentiable function* and a *linearly separable funtion*.  
It is possible to infer considerable information from the gradient uploaded from each party.

### 3.4.2 Privacy-preserving methods

#### Algebraic approaches

Algebraic approaches aim to *protect raw training data* by leveraging the algebraic properties of data transmitted.  
The model parameters of the two parties are *mutually masked*, and only the clear-text gradient is disclosed and used for model updates.  
To defend against the equation-solving attack, approach is proposed by introducing the concept of **k-secure**.  

#### Sparse gradient update approaches

preserve privacy by updating only a subset of gradients.

#### Obfuscation approaches

obfuscate data via randomization, generalization and suppression, which leads to an improvement of privacy at the cost of a deterioration of accuracy.  
approach that applies independent Gaussian random projection (GRP) to protect the raw form of training data.  
The GRP used here also faces a probelm of scalability in terms of both number of participants and attribute dimension.

#### Cryptographic approaches

Cryptographic approaches leverage HE and MPC to preserve the privacy of the gradient of each party in the gradient descent procedure.  
As it could be very computation or communication inefficient, the approximations of nonlinear functions are generally introduced to further trade accuracy for efficiency.  

## 3.5 Summary

Scalability-motivated DML: Parallelism techniques are the major choices  
Privacy-motivated DML: MPC, HE and DP, privacy-preserving gradient descent methods have also been widely used for empowering the privacy-motivated DML.  
FL is a special type of DML  

