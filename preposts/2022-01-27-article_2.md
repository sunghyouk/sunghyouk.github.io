---
layout  : wiki
title   : "Privacy-Preserving Deep Learning for the Detection of Protected Health Information in Real-World Data: Comparative Evaluation"
summary : 
date    : 2022-01-27 17:37:11 +0900
updated : 2022-01-27 17:38:26 +0900
tag     : 
toc     : true
public  : true
parent  : [[index]]
latex   : false
---

# Privacy-Preserving Deep Learning for the Detection of Protected Health Information in Real-World Data: Comparative Evaluation

## Abstract

**Methods**

The training adopts distributed selective stochastic gradient descent.
Five networks were trained on separated real-world clinical data sets by using the privacy-protecting protocol.
In total, the data sets contain 1304 real longitudinal patient records for 296 patients.

**Results**

These networks reached a mean F1 value of 0.955. The gold standard centralized training that is based on the union of all sets and does not take data security into consideration reaches a final value of 0.962.

**Conclusions**

Using real-world clinical data, our study shows that detection of protected health information can be secured by collaborative privacy-preserving training. In general, the approach shows the feasibility of deep learning on distributed and confidential clinical data while ensuring data protection.
