---
layout  : wiki
title   : "An introduction to GLM Chapter 9"
summary : "Chapter 9 Poisson regression and log-linear models"
date    : 2022-01-31 10:38:22 +0900
updated : 2022-02-01 09:35:47 +0900
tag     : 
toc     : true
public  : true
parent  : [[2022-01-10-introduction_GLM]] 
latex   : false
---

# Chapter 9. Poisson regression and log-linear models

## 9.1 Introduction

The number of times an event occurs is a common form of data.  
The Poisson distribution is often used to model count data. If $Y$ is the number of occurrences, its probability distribution:  
$$f(y)=\frac{\mu^y e^{-\mu}}{y!},\,y=0,1,2,...,$$
where $\mu$ is the average number of occurrences.  
Often it needs to be described as a **rate**.  
The **time scale** should be included in the definition.  
More generally, the rate is specified in terms of units of "exposure".  
So the rate may be defined in terms of pearson-year "at risk".  

The events relate to varying amounts of exposure which need to be taken into account when modelling the rate of events. - Poisson regression  
Exposure is constant (and not relevant to the model) and the explanatory variables are usually categorical. The response variable is the frequency or count in each cell of the table. - log-linear model  

## 9.2 Poisson regression

The dependence of $\theta_i$ on the explanatory variables,  
* Equation 9.1
$$\theta_i=e^{\mathbf{x}_i^T\beta}$$

The GLM is  
* Equation 9.2
$$E(Y_i)=\mu_i=n_ie^{\mathbf{x}_i^T\beta};\,Y_i\sim Po(\mu_i)$$

The natural link function is the logarithmic function  
* Equation 9.3
$$\log\mu_i=\log{n_i}+\mathbf{x}_i^T\beta$$
$\log{n_i}$ is called **offset**, known constant, which is readily incorporated into the estimation procedure.  

Hypothesis can be tested using the Wald, score or likelihood ratio statistics.  
* Equation 9.4
$$\frac{b_j-\beta_j}{s.e.(b_j)}\sim N(0, 1)$$
Alternatively, hypothesis testing can be performed by comparing the goodness of fit.  
As var$(Y_i)$=E$(Y_i)$ for the Poisson distribution, the standard error of $Y_i$ is estimated $\sqrt{e_i}$ so the Pearson residuals are  
* Equation 9.5
$$r_i=\frac{o_i-e_i}{\sqrt{e_i}}$$
The deviance for a Poisson model is given in Section 5.6.3.  
* Equation 9.6
$$D=2\sum\left[o_i\log(o_i/e_i)-(o_i-e_i)\right]$$
deviance simplifies to  
* Equation 9.7
$$D=2\sum\left[o_i\log(o_i/e_i)\right]$$
**Deviance residuals** are the component of $D$ in (9.6)  
* Equation 9.8
$$d_i=sign(o_i-e_i)\sqrt{2[o_i\log(o_i/e_i)-(o_i-e_i)]},\, i=1,...,N$$

The goodness of fit statistics $X^2$ and $D$ are closely related. Both can be used directly as measures of goodness of fit, as they can be calculated from the data and the fitted model.  
They can be compared with the central chi-squared distribution with $N-p$ degrees of freedom.  
The chi-squared distribution is likely to be a better approximation for the sampling distribution of $X^2$ (NOTE: Section 7.5).  

Two other summary statistics are the likelihood ratio chi-squared statistic and pseudo $R^2$.  
The likelihood ratio chi-squared statistic $C = 2[l(\mathbf{b})-l(\mathbf{b}_{min})]$ provides an overall test of the hypothesis.  
Less formally, pseudo $R^2 = [l(\mathbf{b}_{min})-l(\mathbf{b})]/l(\mathbf{b}_{min})$ provides an intuitive measure of fit.

### 9.2.1 Example of Poisson regression: British doctors' smoking and coronary death

Building a model  
Calculating Wald statistics  
Calculating C statistics and pseudo $R^2$  

## 9.3 Examples of contingency tables


