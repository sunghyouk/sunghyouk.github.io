---
layout  : wiki
title   : "FL Chapter 5"
summary : "Chapter 5. Vertical FL"
date    : 2022-01-24 11:40:05 +0900
updated : 2022-01-25 13:43:21 +0900
tag     : 
toc     : true
public  : true
parent  : [[2022-01-10-FL_1]]
latex   : false
---

# Chapter 5. Vertical FL

In many practical scenarios, the participants of FL are organizations that collected different data features for the same group of people for pursuing different business goals. - to cooperate to improve business efficiency, which can be considered as B2B paradigm.  

## 5.1 The definition of VFL

The datasets maintained by different organizations having different business goals usually have different feature space, while those organizations may share a large pool of common users.
$$\mathcal{X}_i\neq\mathcal{X}_j,\,\mathcal{Y}_i\neq\mathcal{Y}_j,\,I_i=I_j\,\forall\mathcal{D}_i,\mathcal{D}_j,i\neq j$$
* Underlying assumptions
First, the participants are **honest-but-curious**. - The participants attempt to deduce as much as possible from the information received from other participants, although they abide by the protocol without disturbing it in any way.  
Second, the information transmission process is safe and reliable enough to defend against attacks.  
*Semi-honest third party (STP)*: collects the intermediate results to compute the gradient and loss, and distributes the results to each party.  
The information that the STP recieves from the participants is either encrypted and obfuscated.  

## 5.2 Architecture of VFL

Companies A and B would like to jointly train an ML model. Each of them has their own data. In addition, B also has labeled data that the model needs to perform prediction tasks.  
We assume that C is honest and does not collude with A or B.  
**Part 1**: Encrypted entity alignment. The system uses an encryption-based user ID alignment technique to confirm the common users shared by both parties without A and B exposing their respective raw data.  
**Part 2**: Encrypted model training.  
* Step 1: C creates encryption pairs, and sends the public key to A and B.
* Step 2: A and B encrypt and exchange the intermediate results for gradient and loss calculations.
* Step 3: A and B compute encrypted gradients and add an *additional mask*, respectively. B also computes the encrypted loss. A and B send encrypted results to C.
* Stpe 4: C decrypts gradients and loss and sends the results back to A and B. A and B unmask the gradients, and update the model parameters accordingly.

## 5.3 Algorithms of VFL

### 5.3.1 Secure federated linear regression

using homomorphic encryption  
$\Theta$: local model parameters of each party  
optimization problem:  
* Equation 5.2
$$\min_{\Theta_A, \Theta_B}\sum_i\lVert\Theta_Ax_i^A+\Theta_Bx_i^B-y_i\rVert^2+\frac{\lambda}{2}\left(\lVert\Theta_A\rVert^2+\lVert\Theta_B\rVert^2\right)$$

Let $u_i^A=\Theta_Ax_i^A$, $u_i^B=\Theta_Bx_i^B$, the encrypted loss:  
* Equation 5.3
$$\left[[\mathcal{L}\right]]=\left[\left[\sum_i\left((u_i^A+u_i^B-y_i\right))^2+\frac{\lambda}{2}\left(\lVert\Theta_A\rVert^2+\lVert\Theta_B\rVert^2\right)\right]\right]$$
where the additive HE operation is denoted as $\left[[\cdot\right]]$.  

* Equation 5.4
$$\left[[\mathcal{L}\right]]=\left[[\mathcal{L_A}\right]]+\left[[\mathcal{L_B}\right]]+\left[[\mathcal{L_{AB}}\right]]$$

Let $\left[[\mathcal{d_i}\right]]=\left[[\mathcal{u_i}^A\right]]+\left[[\mathcal{u_i}^B-y_i\right]]$
The gradients of the loss function with respect to the training parameters are given by  
* Equation 5.5, 5.6
$$\left[\left[\partial\mathcal{L}\over\partial{\Theta_A}\right]\right]=2\sum_i\left[[d_i\right]]x_i^A+\left[[\lambda\Theta_A\right]]\\
\left[\left[\partial\mathcal{L}\over{\partial\Theta_B}\right]\right]=2\sum_i\left[[d_i\right]]x_i^B+\left[[\lambda\Theta_B\right]]$$
Note that party A and party B are able to compute $u_i^A$ and $u_i^B$ using only their respective local information.  
As a result, party A and party B should collaboratively compute $d_i$ while preserving the privacy of $u_i^A$ and $u_i^B-y_i$ against the other party, are encrypted via the public key held by a third party C.  
Secret sharing can be applied to remove the third party and decentralize FL.

#### The training process

The training protocol does not reveal any information to C, because all C learns are the masked gradients, and the randomness and secrecy of the masked matrix are guaranteed.  
If a party is malicious and cheats the system by faking its input, the deviation will distort results for the next iteration, thereby alerting the other party who can then terminate the learning process in response.  
At the end of the training process, each party remains oblivious about the data structure of the other party, and it obtains the model parameters associated only with its own features.  
The efficiency of the model depends on the communication overhead and the computation overhead incurred for encrypting the data.  

#### The inference process

* Table 5.3

### 5.3.2 Secure federated tree-boosting

**SecureBoost** provides the same level of accuracy as its non-privacy-preserving variants, while at the same time, reveals no information about each private data owner.

#### Secure entity alignment

First, it aligns the data model under the privacy constraint.- entity alignment, which is to find a common set of data samples.  
Second, it collaboratively learns a shared gradient-tree boosting model

#### Review of XGBoost

1) How can each party compute an updated model based on its local data without reference to class labels?
2) How can the coordinator aggregate all the updated models and obtain a new global model?
3) How to share the updated global model among all parties without leaking any private information at the inference time?

Given a dataset $\mathbf{X}\in\mathbb{R}^{n\times d}$ with $n$ samples and $d$ features, XGBoost predicts the output by using $K$ regression trees:  
* Equation 5.7
$$\hat{y}_i=\sum_{k=1}^Kf_k(\mathbf{x}_i),\,\forall\mathbf{x}_i\in\mathbb{R}^d,\,i=1,2,...,n$$
Objective function at $t$th iteration:  
* Equation 5.8
$$\mathcal{L}^{(t)}\overset{\mathrm{\Delta}}{=}\sum_{i=1}^n\left[l(y_i,\hat{y}_i^{(t-1)})+g_i f_t(\mathbf{x}_i)+\frac{1}{2}h_i f_t^2(\mathbf{x}_i)\right]+\Omega(f_t)$$
where $g_i$ and $h_i$ are two groups of independent variables, and $\Omega(f_t)$ are the complexity of the new tree.  
1) The evaluation of split candidates and the calculation of the optimal weight of a leaf node only depend on the variables $g_i$ and $h_i$
2) The class label is needed for the calculation of $g_i$ and $h_i$

#### The training process of secure boost

The optimal split can be found if the split gain can be calculated for every possible splits, by using the sum of groups of $g_i$ and $h_i$.  
The best split at each party can be found by evaluating all the possible split gains in the coordinator that can hence apply a global optimal split.  
* Algorithm 5.2
After the coordinator obtains the global optimal split, represented as [party id ($i$), feature id ($k$), threshold id ($v$)], it returns the feature id $k$ and threshold id $v$ to the corresponding party $i$.
