---
layout  : wiki
title   : "FL Chapter 5"
summary : "Chapter 5. Vertical FL"
date    : 2022-01-24 11:40:05 +0900
updated : 2022-01-24 17:43:27 +0900
tag     : 
toc     : true
public  : true
parent  : [[2022-01-10-FL_1]]
latex   : false
---

# Chapter 5. Vertical FL

In many practical scenarios, the participants of FL are organizations that collected different data features for the same group of people for pursuing different business goals. - to cooperate to improve business efficiency, which can be considered as B2B paradigm.  

## 5.1 The definition of VFL

The datasets maintained by different organizations having different business goals usually have different feature space, while those organizations may share a large pool of common users.
$$\mathcal{X}_i\neq\mathcal{X}_j,\,\mathcal{Y}_i\neq\mathcal{Y}_j,\,I_i=I_j\,\forall\mathcal{D}_i,\mathcal{D}_j,i\neq j$$
* Underlying assumptions
First, the participants are **honest-but-curious**. - The participants attempt to deduce as much as possible from the information received from other participants, although they abide by the protocol without disturbing it in any way.  
Second, the information transmission process is safe and reliable enough to defend against attacks.  
*Semi-honest third party (STP)*: collects the intermediate results to compute the gradient and loss, and distributes the results to each party.  
The information that the STP recieves from the participants is either encrypted and obfuscated.  

## 5.2 Architecture of VFL

Companies A and B would like to jointly train an ML model. Each of them has their own data. In addition, B also has labeled data that the model needs to perform prediction tasks.  
We assume that C is honest and does not collude with A or B.  
**Part 1**: Encrypted entity alignment. The system uses an encryption-based user ID alignment technique to confirm the common users shared by both parties without A and B exposing their respective raw data.  
**Part 2**: Encrypted model training.  
* Step 1: C creates encryption pairs, and sends the public key to A and B.
* Step 2: A and B encrypt and exchange the intermediate results for gradient and loss calculations.
* Step 3: A and B compute encrypted gradients and add an *additional mask*, respectively. B also computes the encrypted loss. A and B send encrypted results to C.
* Stpe 4: C decrypts gradients and loss and sends the results back to A and B. A and B unmask the gradients, and update the model parameters accordingly.

## 5.3 Algorithms of VFL

### 5.3.1 Secure federated linear regression

using homomorphic encryption  
$\Theta$: local model parameters of each party  
optimization problem:  
* Equation 5.2
$$\min_{\Theta_A, \Theta_B}\sum_i\lVert\Theta_Ax_i^A+\Theta_Bx_i^B-y_i\rVert^2+\frac{\lambda}{2}\left(\lVert\Theta_A\rVert^2+\lVert\Theta_B\rVert^2\right)$$

Let $u_i^A=\Theta_Ax_i^A$, $u_i^B=\Theta_Bx_i^B$, the encrypted loss:  
* Equation 5.3
$$\left[[\mathcal{L}\right]]=\left[\left[\sum_i\left((u_i^A+u_i^B-y_i\right))^2+\frac{\lambda}{2}\left(\lVert\Theta_A\rVert^2+\lVert\Theta_B\rVert^2\right)\right]\right]$$
where the additive HE operation is denoted as $\left[[\cdot\right]]$.  

* Equation 5.4
$$\left[[\mathcal{L}\right]]=\left[[\mathcal{L_A}\right]]+\left[[\mathcal{L_B}\right]]+\left[[\mathcal{L_{AB}}\right]]$$

Let $\left[[\mathcal{d_i}\right]]=\left[[\mathcal{u_i^A}\right]]+\left[[\mathcal{u_i^B-y_i}\right]]$
