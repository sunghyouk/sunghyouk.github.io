---
layout  : wiki
title   : "쏙쏙 들어오는 인공지능 알고리즘 Chapter 10"
summary : "Chapter 10. Q-러닝을 통한 강화학습"
date    : 2022-02-24 10:12:34 +0900
updated : 2022-02-24 11:30:00 +0900
tag     : 
toc     : true
public  : true
parent  : [[2022-01-07-Grokking_AI_algorithm]]
latex   : false
---

## 강화학습이란?

목표가 무엇인지 알고 있지만 목표를 달성하는 데 합당한 행동이 무엇인지 모를 때 유용하다.

## 강화학습에 영감을 주는 요소

강화학습의 또 다른 개념은 즉각적인 만족과 장기적인 결과의 균형을 맞추는 것이다.  
강화학습은 단기 이익보다 장기 이익을 극대화하는 것을 목표로 한다.

## 강화학습이 가능한 문제

강화학습은 개별 행동을 누적해서 더 큰 목표를 달성하는 문제에 가장 유용  
강화학습은 일련의 사건이 좋은 솔루션을 구하는 데 중요한 도메인에서 잘 작동한다.  

## 강화학습 수명 주기

`마르코프 결정 과정`: 현재가 주어졌을 때 과거와 미래가 독립적임

### 시뮬레이션 및 데이터: 환경 활성화

* 환경 초기화
* 환경의 현재 상태 가져오기
* 환경에 행동 적용
* 행동에 대한 보상 계산
* 목표 달성 여부 확인

### Q-러닝을 통한 시뮬레이션 훈련

Q-러닝은 특정 상태에서 유리한 행동에 대한 정보 테이블을 모델링하기 위해 환경의 상태 및 행동을 사용하는 강화학습의 접근 방식이다.  
Q-테이블이라는 보상 테이블을 사용  
Q는 환경에서 행동에 대한 보상 또는 품질을 제공하는 함수를 나타낸다.  

* 초기화
  1) Q-테이블 초기화
  2) 매개변수 설정
    * 임계값에 따른 무작위 행동을 선택할 기회
    * 학습률
    * 즉각적인 만족 또는 장기적인 보상을 선호할지를 결정하는 할인 요인
* n번 반복
  1) 시뮬레이터 초기화
  2) 환경 상태 가져오기
  3) 목표 달성 여부
  4) 무작위 행동 선택
  5) Q-테이블에서 행동 참조
  6) 환경에 행동 적용
  7) Q-테이블 업데이트 - `벨만 방정식`: 현재 상태, 행동, 주어진 행동의 다음 상태, 보상 결과

### 시뮬레이션과 Q-테이블을 통한 테스트

단점은 나머지 부분에 대한 맥락이 없기 때문에 에이전트가 각 행동을 수행할 때 장기 보상보다 단기 보상을 선호한다.

### 훈련 성과 측정

정확하게 측정하려면 문제의 맥락이 필요하다.  
주어진 횟수의 시도에 대해 받은 벌칙 수를 계산  
행동당 평균 보상 - 누적 보상을 총 행동 수로 나누어 계산

### 모델 프리 학습과 모델 기반 학습

모델 프리 학습은 Q-러닝 접근 방식과 유사, 시행착오를 거쳐 다양한 시나리오에서 유리한 행동을 결정하기 위해 환경과 많은 상호 작용을 탐험

## 딥러닝 기반 강화학습

심층 강화학습

## 강화학습 사용 사례

### 로봇 공학

### 추천 엔진

### 금융 거래

### 게임 플레이
